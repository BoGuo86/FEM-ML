{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression - Machine Learning\n",
    "### Last Updated : 03/12/2019, by Hyungmin Jun (hyungminjun@outlook.com)\n",
    "\n",
    "---\n",
    "\n",
    "This script is an open-source, to implement codes for machine learning with TensonFlow under JupyterLab. The original script comes from NeoWizard.\n",
    "Copyright 2019 Hyungmin Jun. All rights reserved.\n",
    "\n",
    "License - GPL version 3\n",
    "This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or any later version. This  program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 0 , cost= 2.0528877 , W= [1.358693] , b= [0.6851523]\n",
      "step= 20 , cost= 0.0437964 , W= [0.8674238] , b= [0.4442579]\n",
      "step= 40 , cost= 0.023269081 , W= [0.8284812] , b= [0.4035076]\n",
      "step= 60 , cost= 0.020983668 , W= [0.83224064] , b= [0.38265198]\n",
      "step= 80 , cost= 0.019056333 , W= [0.8397151] , b= [0.36448854]\n",
      "step= 100 , cost= 0.01730729 , W= [0.8472089] , b= [0.3473418]\n",
      "step= 120 , cost= 0.015718754 , W= [0.85438573] , b= [0.33101648]\n",
      "step= 140 , cost= 0.014276029 , W= [0.86122876] , b= [0.31545976]\n",
      "step= 160 , cost= 0.012965723 , W= [0.8677505] , b= [0.30063424]\n",
      "step= 180 , cost= 0.011775673 , W= [0.8739657] , b= [0.28650552]\n",
      "step= 200 , cost= 0.010694861 , W= [0.87988883] , b= [0.2730409]\n",
      "step= 220 , cost= 0.009713245 , W= [0.8855336] , b= [0.26020905]\n",
      "step= 240 , cost= 0.008821723 , W= [0.89091307] , b= [0.24798019]\n",
      "step= 260 , cost= 0.008012038 , W= [0.8960397] , b= [0.23632605]\n",
      "step= 280 , cost= 0.007276664 , W= [0.9009255] , b= [0.22521958]\n",
      "step= 300 , cost= 0.0066087716 , W= [0.90558165] , b= [0.2146351]\n",
      "step= 320 , cost= 0.0060021826 , W= [0.91001904] , b= [0.20454803]\n",
      "step= 340 , cost= 0.005451281 , W= [0.9142478] , b= [0.194935]\n",
      "step= 360 , cost= 0.004950941 , W= [0.9182778] , b= [0.18577376]\n",
      "step= 380 , cost= 0.004496526 , W= [0.9221184] , b= [0.17704311]\n",
      "step= 400 , cost= 0.004083824 , W= [0.92577857] , b= [0.16872275]\n",
      "step= 420 , cost= 0.003708996 , W= [0.92926663] , b= [0.16079342]\n",
      "step= 440 , cost= 0.0033685698 , W= [0.9325909] , b= [0.15323675]\n",
      "step= 460 , cost= 0.003059388 , W= [0.9357588] , b= [0.1460352]\n",
      "step= 480 , cost= 0.0027785923 , W= [0.93877786] , b= [0.13917215]\n",
      "step= 500 , cost= 0.0025235566 , W= [0.94165516] , b= [0.13263159]\n",
      "step= 520 , cost= 0.0022919395 , W= [0.94439715] , b= [0.12639837]\n",
      "step= 540 , cost= 0.0020815711 , W= [0.9470102] , b= [0.12045811]\n",
      "step= 560 , cost= 0.0018905144 , W= [0.9495006] , b= [0.11479706]\n",
      "step= 580 , cost= 0.0017169937 , W= [0.9518739] , b= [0.10940199]\n",
      "step= 600 , cost= 0.0015594037 , W= [0.95413566] , b= [0.10426048]\n",
      "step= 620 , cost= 0.0014162767 , W= [0.9562911] , b= [0.09936062]\n",
      "step= 640 , cost= 0.0012862856 , W= [0.9583452] , b= [0.09469106]\n",
      "step= 660 , cost= 0.0011682214 , W= [0.9603029] , b= [0.09024096]\n",
      "step= 680 , cost= 0.0010610016 , W= [0.96216846] , b= [0.08599995]\n",
      "step= 700 , cost= 0.0009636151 , W= [0.9639464] , b= [0.08195829]\n",
      "step= 720 , cost= 0.00087517215 , W= [0.9656408] , b= [0.07810654]\n",
      "step= 740 , cost= 0.00079484825 , W= [0.96725553] , b= [0.07443582]\n",
      "step= 760 , cost= 0.00072189077 , W= [0.96879447] , b= [0.07093764]\n",
      "step= 780 , cost= 0.00065563293 , W= [0.97026104] , b= [0.0676038]\n",
      "step= 800 , cost= 0.0005954558 , W= [0.97165865] , b= [0.06442663]\n",
      "step= 820 , cost= 0.0005408034 , W= [0.9729906] , b= [0.0613988]\n",
      "step= 840 , cost= 0.0004911651 , W= [0.97426] , b= [0.05851327]\n",
      "step= 860 , cost= 0.00044608387 , W= [0.97546965] , b= [0.05576332]\n",
      "step= 880 , cost= 0.00040514302 , W= [0.97662246] , b= [0.05314264]\n",
      "step= 900 , cost= 0.00036795367 , W= [0.97772115] , b= [0.05064511]\n",
      "step= 920 , cost= 0.00033418267 , W= [0.9787681] , b= [0.04826497]\n",
      "step= 940 , cost= 0.0003035119 , W= [0.9797659] , b= [0.04599675]\n",
      "step= 960 , cost= 0.00027565318 , W= [0.9807169] , b= [0.04383509]\n",
      "step= 980 , cost= 0.00025035365 , W= [0.9816231] , b= [0.04177499]\n",
      "step= 1000 , cost= 0.00022737385 , W= [0.9824868] , b= [0.03981171]\n",
      "step= 1020 , cost= 0.00020650351 , W= [0.9833098] , b= [0.0379407]\n",
      "step= 1040 , cost= 0.00018755144 , W= [0.9840942] , b= [0.03615762]\n",
      "step= 1060 , cost= 0.00017033587 , W= [0.98484164] , b= [0.03445837]\n",
      "step= 1080 , cost= 0.0001547023 , W= [0.98555404] , b= [0.032839]\n",
      "step= 1100 , cost= 0.0001405031 , W= [0.986233] , b= [0.03129569]\n",
      "step= 1120 , cost= 0.00012760771 , W= [0.98688] , b= [0.02982488]\n",
      "step= 1140 , cost= 0.00011589547 , W= [0.98749655] , b= [0.0284232]\n",
      "step= 1160 , cost= 0.00010525878 , W= [0.98808414] , b= [0.02708745]\n",
      "step= 1180 , cost= 9.559671e-05 , W= [0.9886441] , b= [0.02581447]\n",
      "step= 1200 , cost= 8.682368e-05 , W= [0.9891779] , b= [0.02460129]\n",
      "step= 1220 , cost= 7.885496e-05 , W= [0.9896863] , b= [0.02344519]\n",
      "step= 1240 , cost= 7.161791e-05 , W= [0.990171] , b= [0.02234343]\n",
      "step= 1260 , cost= 6.50443e-05 , W= [0.990633] , b= [0.02129336]\n",
      "step= 1280 , cost= 5.907314e-05 , W= [0.99107325] , b= [0.02029265]\n",
      "step= 1300 , cost= 5.3651707e-05 , W= [0.9914928] , b= [0.01933896]\n",
      "step= 1320 , cost= 4.8727914e-05 , W= [0.9918926] , b= [0.0184301]\n",
      "step= 1340 , cost= 4.425486e-05 , W= [0.99227357] , b= [0.01756396]\n",
      "step= 1360 , cost= 4.0193107e-05 , W= [0.99263674] , b= [0.01673851]\n",
      "step= 1380 , cost= 3.6504596e-05 , W= [0.99298275] , b= [0.01595184]\n",
      "step= 1400 , cost= 3.3153814e-05 , W= [0.99331254] , b= [0.01520216]\n",
      "step= 1420 , cost= 3.0110677e-05 , W= [0.99362683] , b= [0.01448773]\n",
      "step= 1440 , cost= 2.7347089e-05 , W= [0.99392635] , b= [0.01380685]\n",
      "step= 1460 , cost= 2.4836316e-05 , W= [0.9942118] , b= [0.01315798]\n",
      "step= 1480 , cost= 2.255765e-05 , W= [0.9944838] , b= [0.01253961]\n",
      "step= 1500 , cost= 2.0486723e-05 , W= [0.9947431] , b= [0.0119503]\n",
      "step= 1520 , cost= 1.8606315e-05 , W= [0.9949901] , b= [0.01138869]\n",
      "step= 1540 , cost= 1.6898215e-05 , W= [0.99522555] , b= [0.01085343]\n",
      "step= 1560 , cost= 1.5347998e-05 , W= [0.99544996] , b= [0.01034336]\n",
      "step= 1580 , cost= 1.3939013e-05 , W= [0.99566376] , b= [0.00985726]\n",
      "step= 1600 , cost= 1.2659651e-05 , W= [0.99586755] , b= [0.00939402]\n",
      "step= 1620 , cost= 1.1497741e-05 , W= [0.99606174] , b= [0.00895254]\n",
      "step= 1640 , cost= 1.0442022e-05 , W= [0.9962469] , b= [0.00853179]\n",
      "step= 1660 , cost= 9.483858e-06 , W= [0.99642324] , b= [0.00813083]\n",
      "step= 1680 , cost= 8.613618e-06 , W= [0.9965913] , b= [0.00774871]\n",
      "step= 1700 , cost= 7.822856e-06 , W= [0.99675155] , b= [0.00738453]\n",
      "step= 1720 , cost= 7.1048366e-06 , W= [0.9969042] , b= [0.00703748]\n",
      "step= 1740 , cost= 6.4528454e-06 , W= [0.9970497] , b= [0.00670675]\n",
      "step= 1760 , cost= 5.860516e-06 , W= [0.9971884] , b= [0.00639155]\n",
      "step= 1780 , cost= 5.3226104e-06 , W= [0.9973205] , b= [0.00609117]\n",
      "step= 1800 , cost= 4.8339625e-06 , W= [0.99744636] , b= [0.00580493]\n",
      "step= 1820 , cost= 4.3905115e-06 , W= [0.9975664] , b= [0.00553213]\n",
      "step= 1840 , cost= 3.9873066e-06 , W= [0.9976808] , b= [0.00527214]\n",
      "step= 1860 , cost= 3.621416e-06 , W= [0.9977898] , b= [0.00502437]\n",
      "step= 1880 , cost= 3.289062e-06 , W= [0.99789363] , b= [0.00478823]\n",
      "step= 1900 , cost= 2.9871323e-06 , W= [0.99799263] , b= [0.0045632]\n",
      "step= 1920 , cost= 2.712797e-06 , W= [0.998087] , b= [0.00434875]\n",
      "step= 1940 , cost= 2.4638564e-06 , W= [0.9981769] , b= [0.00414438]\n",
      "step= 1960 , cost= 2.2377787e-06 , W= [0.9982625] , b= [0.00394962]\n",
      "step= 1980 , cost= 2.032545e-06 , W= [0.9983442] , b= [0.00376402]\n",
      "step= 2000 , cost= 1.8460642e-06 , W= [0.998422] , b= [0.00358713]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# X and Y data\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# Cost / loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minime the cost function by gradient descent method\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train     = optimizer.minimize(cost)\n",
    "\n",
    "# Open and initialize the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Run the session\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print('step=', step, ', cost=', sess.run(cost), ', W=', sess.run(W), ', b=', sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**With placeholder for X and Y data**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 0 , cost= 0.26192936 , W= [0.62353075] , b= [0.40745428]\n",
      "step= 20 , cost= 0.0322557 , W= [0.78297323] , b= [0.45066136]\n",
      "step= 40 , cost= 0.027430698 , W= [0.80667007] , b= [0.43541944]\n",
      "step= 60 , cost= 0.024896095 , W= [0.8170411] , b= [0.41552165]\n",
      "step= 80 , cost= 0.022610882 , W= [0.82576185] , b= [0.39604744]\n",
      "step= 100 , cost= 0.02053556 , W= [0.833962] , b= [0.3774398]\n",
      "step= 120 , cost= 0.01865074 , W= [0.84176636] , b= [0.35970202]\n",
      "step= 140 , cost= 0.016938897 , W= [0.8492028] , b= [0.34279746]\n",
      "step= 160 , cost= 0.015384167 , W= [0.8562897] , b= [0.32668725]\n",
      "step= 180 , cost= 0.013972156 , W= [0.86304355] , b= [0.31133416]\n",
      "step= 200 , cost= 0.012689746 , W= [0.86947995] , b= [0.29670268]\n",
      "step= 220 , cost= 0.011525027 , W= [0.875614] , b= [0.28275874]\n",
      "step= 240 , cost= 0.010467232 , W= [0.8814596] , b= [0.26947016]\n",
      "step= 260 , cost= 0.009506506 , W= [0.8870305] , b= [0.25680608]\n",
      "step= 280 , cost= 0.008633956 , W= [0.89233977] , b= [0.24473712]\n",
      "step= 300 , cost= 0.007841482 , W= [0.8973993] , b= [0.2332354]\n",
      "step= 320 , cost= 0.0071217804 , W= [0.9022212] , b= [0.22227423]\n",
      "step= 340 , cost= 0.0064681037 , W= [0.9068164] , b= [0.21182814]\n",
      "step= 360 , cost= 0.0058744424 , W= [0.9111957] , b= [0.20187303]\n",
      "step= 380 , cost= 0.005335255 , W= [0.91536915] , b= [0.19238576]\n",
      "step= 400 , cost= 0.004845576 , W= [0.91934645] , b= [0.18334441]\n",
      "step= 420 , cost= 0.0044008377 , W= [0.92313683] , b= [0.17472792]\n",
      "step= 440 , cost= 0.003996906 , W= [0.92674917] , b= [0.16651635]\n",
      "step= 460 , cost= 0.0036300484 , W= [0.9301917] , b= [0.1586907]\n",
      "step= 480 , cost= 0.003296876 , W= [0.93347245] , b= [0.15123284]\n",
      "step= 500 , cost= 0.002994269 , W= [0.93659896] , b= [0.14412543]\n",
      "step= 520 , cost= 0.0027194463 , W= [0.9395786] , b= [0.13735211]\n",
      "step= 540 , cost= 0.0024698416 , W= [0.94241816] , b= [0.13089705]\n",
      "step= 560 , cost= 0.002243154 , W= [0.9451243] , b= [0.12474538]\n",
      "step= 580 , cost= 0.002037272 , W= [0.9477032] , b= [0.11888283]\n",
      "step= 600 , cost= 0.001850282 , W= [0.950161] , b= [0.11329584]\n",
      "step= 620 , cost= 0.0016804558 , W= [0.9525032] , b= [0.10797137]\n",
      "step= 640 , cost= 0.0015262184 , W= [0.9547354] , b= [0.10289712]\n",
      "step= 660 , cost= 0.0013861369 , W= [0.95686257] , b= [0.09806138]\n",
      "step= 680 , cost= 0.001258915 , W= [0.95888984] , b= [0.09345289]\n",
      "step= 700 , cost= 0.0011433669 , W= [0.9608219] , b= [0.08906099]\n",
      "step= 720 , cost= 0.0010384228 , W= [0.9626631] , b= [0.08487548]\n",
      "step= 740 , cost= 0.0009431129 , W= [0.9644178] , b= [0.08088664]\n",
      "step= 760 , cost= 0.00085655256 , W= [0.9660901] , b= [0.07708528]\n",
      "step= 780 , cost= 0.0007779298 , W= [0.96768373] , b= [0.07346255]\n",
      "step= 800 , cost= 0.00070653454 , W= [0.9692023] , b= [0.07001011]\n",
      "step= 820 , cost= 0.00064168574 , W= [0.9706498] , b= [0.06671994]\n",
      "step= 840 , cost= 0.00058278587 , W= [0.97202915] , b= [0.06358434]\n",
      "step= 860 , cost= 0.0005292961 , W= [0.9733437] , b= [0.06059612]\n",
      "step= 880 , cost= 0.0004807144 , W= [0.97459644] , b= [0.05774833]\n",
      "step= 900 , cost= 0.0004365923 , W= [0.9757903] , b= [0.05503434]\n",
      "step= 920 , cost= 0.00039652025 , W= [0.97692806] , b= [0.05244793]\n",
      "step= 940 , cost= 0.00036012847 , W= [0.9780123] , b= [0.0499831]\n",
      "step= 960 , cost= 0.00032707406 , W= [0.9790456] , b= [0.04763409]\n",
      "step= 980 , cost= 0.00029705468 , W= [0.98003036] , b= [0.04539552]\n",
      "step= 1000 , cost= 0.0002697894 , W= [0.98096895] , b= [0.04326208]\n",
      "step= 1020 , cost= 0.00024502666 , W= [0.9818634] , b= [0.04122889]\n",
      "step= 1040 , cost= 0.00022253691 , W= [0.9827157] , b= [0.03929126]\n",
      "step= 1060 , cost= 0.0002021115 , W= [0.983528] , b= [0.0374447]\n",
      "step= 1080 , cost= 0.00018356154 , W= [0.9843021] , b= [0.03568495]\n",
      "step= 1100 , cost= 0.00016671391 , W= [0.98503995] , b= [0.03400787]\n",
      "step= 1120 , cost= 0.0001514117 , W= [0.985743] , b= [0.0324096]\n",
      "step= 1140 , cost= 0.0001375144 , W= [0.986413] , b= [0.03088646]\n",
      "step= 1160 , cost= 0.00012489337 , W= [0.9870516] , b= [0.0294349]\n",
      "step= 1180 , cost= 0.00011342983 , W= [0.98766005] , b= [0.02805155]\n",
      "step= 1200 , cost= 0.00010301745 , W= [0.98824] , b= [0.02673325]\n",
      "step= 1220 , cost= 9.356421e-05 , W= [0.9887926] , b= [0.02547691]\n",
      "step= 1240 , cost= 8.497599e-05 , W= [0.98931926] , b= [0.02427964]\n",
      "step= 1260 , cost= 7.71755e-05 , W= [0.9898213] , b= [0.02313858]\n",
      "step= 1280 , cost= 7.0091555e-05 , W= [0.9902998] , b= [0.02205107]\n",
      "step= 1300 , cost= 6.365889e-05 , W= [0.9907556] , b= [0.0210147]\n",
      "step= 1320 , cost= 5.781597e-05 , W= [0.9911901] , b= [0.02002707]\n",
      "step= 1340 , cost= 5.2508287e-05 , W= [0.9916041] , b= [0.01908585]\n",
      "step= 1360 , cost= 4.7689042e-05 , W= [0.9919987] , b= [0.01818888]\n",
      "step= 1380 , cost= 4.3312015e-05 , W= [0.9923747] , b= [0.01733406]\n",
      "step= 1400 , cost= 3.9337225e-05 , W= [0.99273306] , b= [0.01651941]\n",
      "step= 1420 , cost= 3.572676e-05 , W= [0.9930746] , b= [0.01574306]\n",
      "step= 1440 , cost= 3.244696e-05 , W= [0.99340004] , b= [0.0150032]\n",
      "step= 1460 , cost= 2.9469287e-05 , W= [0.9937102] , b= [0.01429812]\n",
      "step= 1480 , cost= 2.6764394e-05 , W= [0.9940058] , b= [0.01362616]\n",
      "step= 1500 , cost= 2.430722e-05 , W= [0.99428755] , b= [0.01298579]\n",
      "step= 1520 , cost= 2.207641e-05 , W= [0.994556] , b= [0.0123755]\n",
      "step= 1540 , cost= 2.0050766e-05 , W= [0.99481183] , b= [0.01179391]\n",
      "step= 1560 , cost= 1.8210723e-05 , W= [0.9950556] , b= [0.01123966]\n",
      "step= 1580 , cost= 1.6539198e-05 , W= [0.995288] , b= [0.01071145]\n",
      "step= 1600 , cost= 1.5020832e-05 , W= [0.99550945] , b= [0.01020806]\n",
      "step= 1620 , cost= 1.3641872e-05 , W= [0.9957205] , b= [0.00972831]\n",
      "step= 1640 , cost= 1.2390136e-05 , W= [0.9959216] , b= [0.0092711]\n",
      "step= 1660 , cost= 1.1252837e-05 , W= [0.9961133] , b= [0.00883541]\n",
      "step= 1680 , cost= 1.0219907e-05 , W= [0.9962959] , b= [0.00842019]\n",
      "step= 1700 , cost= 9.282154e-06 , W= [0.99647] , b= [0.00802449]\n",
      "step= 1720 , cost= 8.430163e-06 , W= [0.99663585] , b= [0.00764741]\n",
      "step= 1740 , cost= 7.656382e-06 , W= [0.996794] , b= [0.00728803]\n",
      "step= 1760 , cost= 6.95384e-06 , W= [0.99694467] , b= [0.00694553]\n",
      "step= 1780 , cost= 6.3156454e-06 , W= [0.99708825] , b= [0.00661912]\n",
      "step= 1800 , cost= 5.7357465e-06 , W= [0.99722505] , b= [0.00630804]\n",
      "step= 1820 , cost= 5.2094815e-06 , W= [0.99735546] , b= [0.0060116]\n",
      "step= 1840 , cost= 4.731436e-06 , W= [0.99747974] , b= [0.0057291]\n",
      "step= 1860 , cost= 4.2969673e-06 , W= [0.99759823] , b= [0.00545986]\n",
      "step= 1880 , cost= 3.902395e-06 , W= [0.99771106] , b= [0.00520325]\n",
      "step= 1900 , cost= 3.5442743e-06 , W= [0.9978186] , b= [0.00495874]\n",
      "step= 1920 , cost= 3.2193584e-06 , W= [0.9979211] , b= [0.00472571]\n",
      "step= 1940 , cost= 2.9237929e-06 , W= [0.9980188] , b= [0.00450365]\n",
      "step= 1960 , cost= 2.6554874e-06 , W= [0.99811196] , b= [0.00429199]\n",
      "step= 1980 , cost= 2.4118078e-06 , W= [0.99820065] , b= [0.00409028]\n",
      "step= 2000 , cost= 2.1902006e-06 , W= [0.99828523] , b= [0.00389805]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# X and Y data\n",
    "X = tf.placeholder(tf.float32, shape = [None])\n",
    "Y = tf.placeholder(tf.float32, shape = [None])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# Cost / loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "# Minime the cost function by gradient descent method\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train     = optimizer.minimize(cost)\n",
    "\n",
    "# Open and initialize the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Run the session\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], feed_dict={X: [1, 2, 3], Y: [1, 2, 3]})\n",
    "    if step % 20 == 0:\n",
    "        print('step=', step, ', cost=', cost_val, ', W=', W_val, ', b=', b_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Plot cost function**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# X and Y data\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "b = 0\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# Cost / loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Open and initialize the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Variables for plotting the cost function\n",
    "W_val    = []\n",
    "cost_val = []\n",
    "\n",
    "# Run the session\n",
    "for i in range(-30, 50):\n",
    "    feed_W = i * 0.1\n",
    "    curr_cost, curr_W = sess.run([cost, W], feed_dict = {W: feed_W})\n",
    "    cost_val.append(curr_cost)\n",
    "    W_val.append(curr_W)\n",
    "    \n",
    "# Plot the cost function\n",
    "plt.plot(W_val, cost_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**The use of derivative instead of gradient descent functionn**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 0 , cost= 0.191714 , W= [0.89190084]\n",
      "step= 1 , cost= 0.05453199 , W= [0.9423471]\n",
      "step= 2 , cost= 0.01551132 , W= [0.9692518]\n",
      "step= 3 , cost= 0.0044121086 , W= [0.983601]\n",
      "step= 4 , cost= 0.0012550014 , W= [0.99125385]\n",
      "step= 5 , cost= 0.0003569771 , W= [0.9953354]\n",
      "step= 6 , cost= 0.00010153907 , W= [0.9975122]\n",
      "step= 7 , cost= 2.8882792e-05 , W= [0.9986732]\n",
      "step= 8 , cost= 8.215185e-06 , W= [0.9992924]\n",
      "step= 9 , cost= 2.3367636e-06 , W= [0.9996226]\n",
      "step= 10 , cost= 6.6473535e-07 , W= [0.9997987]\n",
      "step= 11 , cost= 1.8909681e-07 , W= [0.99989265]\n",
      "step= 12 , cost= 5.378953e-08 , W= [0.9999428]\n",
      "step= 13 , cost= 1.5279511e-08 , W= [0.9999695]\n",
      "step= 14 , cost= 4.346172e-09 , W= [0.9999837]\n",
      "step= 15 , cost= 1.2375819e-09 , W= [0.9999913]\n",
      "step= 16 , cost= 3.5548453e-10 , W= [0.99999535]\n",
      "step= 17 , cost= 9.976494e-11 , W= [0.9999975]\n",
      "step= 18 , cost= 2.984753e-11 , W= [0.9999987]\n",
      "step= 19 , cost= 7.716494e-12 , W= [0.9999993]\n",
      "step= 20 , cost= 2.3874236e-12 , W= [0.99999964]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# X and Y data\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None])\n",
    "Y = tf.placeholder(tf.float32, shape = [None])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = X * W\n",
    "\n",
    "# Cost / loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Gradient descent using derivative; W = W - learning_rate * derivative\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent  = W - learning_rate * gradient\n",
    "update   = W.assign(descent)\n",
    "\n",
    "# Open and initialize the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Run the session\n",
    "for step in range(21):\n",
    "    cost_val, W_val, _ = sess.run([cost, W, update], feed_dict={X: x_data, Y: y_data})\n",
    "    print('step=', step, ', cost=', cost_val, ', W=', W_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Linear regression with multivariables**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 0 , cost= 71300.53\n",
      "step= 10 , cost= 7.2333937\n",
      "step= 20 , cost= 6.546978\n",
      "step= 30 , cost= 6.513354\n",
      "step= 40 , cost= 6.4799147\n",
      "step= 50 , cost= 6.4466944\n",
      "step= 60 , cost= 6.4136415\n",
      "step= 70 , cost= 6.3807383\n",
      "step= 80 , cost= 6.3480186\n",
      "step= 90 , cost= 6.3154616\n",
      "step= 100 , cost= 6.283139\n",
      "step= 110 , cost= 6.2509356\n",
      "step= 120 , cost= 6.2189384\n",
      "step= 130 , cost= 6.187104\n",
      "step= 140 , cost= 6.155431\n",
      "step= 150 , cost= 6.123943\n",
      "step= 160 , cost= 6.092622\n",
      "step= 170 , cost= 6.061488\n",
      "step= 180 , cost= 6.0305\n",
      "step= 190 , cost= 5.9996605\n",
      "step= 200 , cost= 5.9690027\n",
      "step= 210 , cost= 5.9385056\n",
      "step= 220 , cost= 5.9082108\n",
      "step= 230 , cost= 5.87806\n",
      "step= 240 , cost= 5.8480515\n",
      "step= 250 , cost= 5.818194\n",
      "step= 260 , cost= 5.7885327\n",
      "step= 270 , cost= 5.7590213\n",
      "step= 280 , cost= 5.729665\n",
      "step= 290 , cost= 5.700479\n",
      "step= 300 , cost= 5.671426\n",
      "step= 310 , cost= 5.6425443\n",
      "step= 320 , cost= 5.6138062\n",
      "step= 330 , cost= 5.5852413\n",
      "step= 340 , cost= 5.5568285\n",
      "step= 350 , cost= 5.5285773\n",
      "step= 360 , cost= 5.5004244\n",
      "step= 370 , cost= 5.472473\n",
      "step= 380 , cost= 5.4446516\n",
      "step= 390 , cost= 5.4170074\n",
      "step= 400 , cost= 5.3894906\n",
      "step= 410 , cost= 5.362113\n",
      "step= 420 , cost= 5.3348956\n",
      "step= 430 , cost= 5.307831\n",
      "step= 440 , cost= 5.2809057\n",
      "step= 450 , cost= 5.2541513\n",
      "step= 460 , cost= 5.227495\n",
      "step= 470 , cost= 5.201029\n",
      "step= 480 , cost= 5.1746855\n",
      "step= 490 , cost= 5.1484423\n",
      "step= 500 , cost= 5.1223917\n",
      "step= 510 , cost= 5.096477\n",
      "step= 520 , cost= 5.07068\n",
      "step= 530 , cost= 5.045053\n",
      "step= 540 , cost= 5.0195303\n",
      "step= 550 , cost= 4.994157\n",
      "step= 560 , cost= 4.9689384\n",
      "step= 570 , cost= 4.943851\n",
      "step= 580 , cost= 4.9188604\n",
      "step= 590 , cost= 4.8940263\n",
      "step= 600 , cost= 4.869378\n",
      "step= 610 , cost= 4.8447714\n",
      "step= 620 , cost= 4.820372\n",
      "step= 630 , cost= 4.7960668\n",
      "step= 640 , cost= 4.771895\n",
      "step= 650 , cost= 4.7478786\n",
      "step= 660 , cost= 4.723965\n",
      "step= 670 , cost= 4.7001824\n",
      "step= 680 , cost= 4.6765337\n",
      "step= 690 , cost= 4.652987\n",
      "step= 700 , cost= 4.6296387\n",
      "step= 710 , cost= 4.6063476\n",
      "step= 720 , cost= 4.5831957\n",
      "step= 730 , cost= 4.560175\n",
      "step= 740 , cost= 4.537303\n",
      "step= 750 , cost= 4.5145235\n",
      "step= 760 , cost= 4.491866\n",
      "step= 770 , cost= 4.4693403\n",
      "step= 780 , cost= 4.446935\n",
      "step= 790 , cost= 4.424654\n",
      "step= 800 , cost= 4.4024744\n",
      "step= 810 , cost= 4.3804398\n",
      "step= 820 , cost= 4.358518\n",
      "step= 830 , cost= 4.3367243\n",
      "step= 840 , cost= 4.3150206\n",
      "step= 850 , cost= 4.293466\n",
      "step= 860 , cost= 4.271992\n",
      "step= 870 , cost= 4.2506332\n",
      "step= 880 , cost= 4.22943\n",
      "step= 890 , cost= 4.2083063\n",
      "step= 900 , cost= 4.187289\n",
      "step= 910 , cost= 4.1664124\n",
      "step= 920 , cost= 4.1456504\n",
      "step= 930 , cost= 4.124981\n",
      "step= 940 , cost= 4.1044397\n",
      "step= 950 , cost= 4.083994\n",
      "step= 960 , cost= 4.06368\n",
      "step= 970 , cost= 4.0434594\n",
      "step= 980 , cost= 4.0233264\n",
      "step= 990 , cost= 4.003343\n",
      "step= 1000 , cost= 3.9834313\n",
      "step= 1010 , cost= 3.9636674\n",
      "step= 1020 , cost= 3.943962\n",
      "step= 1030 , cost= 3.9244225\n",
      "step= 1040 , cost= 3.9049087\n",
      "step= 1050 , cost= 3.8855636\n",
      "step= 1060 , cost= 3.8663125\n",
      "step= 1070 , cost= 3.8471527\n",
      "step= 1080 , cost= 3.8280876\n",
      "step= 1090 , cost= 3.8091438\n",
      "step= 1100 , cost= 3.790284\n",
      "step= 1110 , cost= 3.7715392\n",
      "step= 1120 , cost= 3.75288\n",
      "step= 1130 , cost= 3.7343698\n",
      "step= 1140 , cost= 3.7158828\n",
      "step= 1150 , cost= 3.6975644\n",
      "step= 1160 , cost= 3.6793094\n",
      "step= 1170 , cost= 3.661145\n",
      "step= 1180 , cost= 3.6431053\n",
      "step= 1190 , cost= 3.6251311\n",
      "step= 1200 , cost= 3.607286\n",
      "step= 1210 , cost= 3.5895333\n",
      "step= 1220 , cost= 3.5718608\n",
      "step= 1230 , cost= 3.5542698\n",
      "step= 1240 , cost= 3.5368226\n",
      "step= 1250 , cost= 3.5194275\n",
      "step= 1260 , cost= 3.5021317\n",
      "step= 1270 , cost= 3.4849567\n",
      "step= 1280 , cost= 3.4678502\n",
      "step= 1290 , cost= 3.450819\n",
      "step= 1300 , cost= 3.4338975\n",
      "step= 1310 , cost= 3.4170647\n",
      "step= 1320 , cost= 3.4003315\n",
      "step= 1330 , cost= 3.3837006\n",
      "step= 1340 , cost= 3.367106\n",
      "step= 1350 , cost= 3.3506565\n",
      "step= 1360 , cost= 3.3342652\n",
      "step= 1370 , cost= 3.3179889\n",
      "step= 1380 , cost= 3.3017578\n",
      "step= 1390 , cost= 3.2856648\n",
      "step= 1400 , cost= 3.269628\n",
      "step= 1410 , cost= 3.2536864\n",
      "step= 1420 , cost= 3.237822\n",
      "step= 1430 , cost= 3.2220352\n",
      "step= 1440 , cost= 3.2063541\n",
      "step= 1450 , cost= 3.190756\n",
      "step= 1460 , cost= 3.175237\n",
      "step= 1470 , cost= 3.1597881\n",
      "step= 1480 , cost= 3.1444328\n",
      "step= 1490 , cost= 3.1291623\n",
      "step= 1500 , cost= 3.113992\n",
      "step= 1510 , cost= 3.0988953\n",
      "step= 1520 , cost= 3.0838656\n",
      "step= 1530 , cost= 3.0689108\n",
      "step= 1540 , cost= 3.0540166\n",
      "step= 1550 , cost= 3.0392432\n",
      "step= 1560 , cost= 3.0245442\n",
      "step= 1570 , cost= 3.0099258\n",
      "step= 1580 , cost= 2.995357\n",
      "step= 1590 , cost= 2.9809113\n",
      "step= 1600 , cost= 2.9665093\n",
      "step= 1610 , cost= 2.9521995\n",
      "step= 1620 , cost= 2.9379654\n",
      "step= 1630 , cost= 2.9238083\n",
      "step= 1640 , cost= 2.9097266\n",
      "step= 1650 , cost= 2.8956943\n",
      "step= 1660 , cost= 2.8817735\n",
      "step= 1670 , cost= 2.8679085\n",
      "step= 1680 , cost= 2.8541324\n",
      "step= 1690 , cost= 2.8404243\n",
      "step= 1700 , cost= 2.8267732\n",
      "step= 1710 , cost= 2.8132284\n",
      "step= 1720 , cost= 2.7997181\n",
      "step= 1730 , cost= 2.786291\n",
      "step= 1740 , cost= 2.772965\n",
      "step= 1750 , cost= 2.7596936\n",
      "step= 1760 , cost= 2.7464986\n",
      "step= 1770 , cost= 2.733355\n",
      "step= 1780 , cost= 2.7202942\n",
      "step= 1790 , cost= 2.7073112\n",
      "step= 1800 , cost= 2.6943903\n",
      "step= 1810 , cost= 2.6815343\n",
      "step= 1820 , cost= 2.668758\n",
      "step= 1830 , cost= 2.6560452\n",
      "step= 1840 , cost= 2.6433961\n",
      "step= 1850 , cost= 2.630814\n",
      "step= 1860 , cost= 2.618318\n",
      "step= 1870 , cost= 2.6058738\n",
      "step= 1880 , cost= 2.5934901\n",
      "step= 1890 , cost= 2.5811858\n",
      "step= 1900 , cost= 2.5689404\n",
      "step= 1910 , cost= 2.5567653\n",
      "step= 1920 , cost= 2.5446405\n",
      "step= 1930 , cost= 2.5326068\n",
      "step= 1940 , cost= 2.5206158\n",
      "step= 1950 , cost= 2.5087047\n",
      "step= 1960 , cost= 2.4968567\n",
      "step= 1970 , cost= 2.4850564\n",
      "step= 1980 , cost= 2.473322\n",
      "step= 1990 , cost= 2.46167\n",
      "step= 2000 , cost= 2.4500592\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# X and Y data\n",
    "x_data = [[73., 80., 75.], [93., 88., 93.], [89., 91., 90.], [96., 98., 100.], [73., 66., 70.,]]\n",
    "y_data = [[152],           [185.],          [180.],          [196.],           [142.,]]\n",
    "\n",
    "# Define placeholders\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]),    name = 'bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Cost / loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minime the cost function by gradient descent method\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train     = optimizer.minimize(cost)\n",
    "\n",
    "# Open and initialize the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Run the session\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], feed_dict = {X: x_data, Y: y_data})\n",
    "    if step % 10 == 0:\n",
    "        print('step=', step, ', cost=', cost_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
