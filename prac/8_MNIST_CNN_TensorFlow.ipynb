{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nClassification - MNIST with CNN model usign TensorFlow\\nLast Updated : 04/05/2019, by Hyungmin Jun (hyungminjun@outlook.com)\\n\\n=============================================================================\\n\\nCopyright 2019 Hyungmin Jun. All rights reserved.\\n\\nLicense - GPL version 3\\nThis program is free software: you can redistribute it and/or modify it under\\nthe terms of the GNU General Public License as published by the Free Software\\nFoundation, either version 3 of the License, or any later version. This\\nprogram is distributed in the hope that it will be useful, but WITHOUT ANY\\nWARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR\\nA PARTICULAR PURPOSE. See the GNU General Public License for more details.\\nYou should have received a copy of the GNU General Public License along with\\nthis program. If not, see <http://www.gnu.org/licenses/>.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Classification - MNIST with CNN model usign TensorFlow\n",
    "Last Updated : 04/05/2019, by Hyungmin Jun (hyungminjun@outlook.com)\n",
    "\n",
    "=============================================================================\n",
    "\n",
    "Copyright 2019 Hyungmin Jun. All rights reserved.\n",
    "\n",
    "License - GPL version 3\n",
    "This program is free software: you can redistribute it and/or modify it under\n",
    "the terms of the GNU General Public License as published by the Free Software\n",
    "Foundation, either version 3 of the License, or any later version. This\n",
    "program is distributed in the hope that it will be useful, but WITHOUT ANY\n",
    "WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR\n",
    "A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
    "You should have received a copy of the GNU General Public License along with\n",
    "this program. If not, see <http://www.gnu.org/licenses/>.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from datetime import datetime\n",
    "\n",
    "mnist = input_data.read_data_sets(\"../data/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"train image shape = \", np.shape(mnist.train.images))\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
    "print(\"test image shape = \",  np.shape(mnist.test.images))\n",
    "print(\"test label shape = \",  np.shape(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter\n",
    "learning_rate = 0.01\n",
    "epochs        = 30\n",
    "batch_size    = 100\n",
    "\n",
    "# Set the placeholder for input and output\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "T = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Input layer and reshape for convolution\n",
    "# ==================================================\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # Image size 28 by 28 by 1 (gray image)\n",
    "\n",
    "# ==================================================\n",
    "# 1st convolution layer, using 3 by 3 with 32 filters\n",
    "# ==================================================\n",
    "F2 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "B2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "\n",
    "# 28 by 28 by 1 to 28 by 28 by 32\n",
    "C2 = tf.nn.conv2d(A1, F2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# Relu activation function\n",
    "Z2 = tf.nn.relu(C2 + B2)\n",
    "\n",
    "# Max pooling; 28 by 28 by 32 to 14 by 14 by 32\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# ==================================================\n",
    "# 2nd convolution layer, using 3 by 3 with 64 filters\n",
    "# ==================================================\n",
    "F3 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "B3 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "\n",
    "# 14 by 14 by 32 to 14 by 14 by 64\n",
    "C3 = tf.nn.conv2d(A2, F3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# Relu activation function\n",
    "Z3 = tf.nn.relu(C3 + B3)\n",
    "\n",
    "# Max pooling; 14 by 14 by 64 to 7 by 7 by 64\n",
    "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# ==================================================\n",
    "# 3rd convolution layer, using 3 by 3 with 128 filters\n",
    "# ==================================================\n",
    "F4 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "B4 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "\n",
    "# 7 by 7 by 64 to 7 by 7 by 128\n",
    "C4 = tf.nn.conv2d(A3, F4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# Relu activation function\n",
    "Z4 = tf.nn.relu(C4 + B4)\n",
    "\n",
    "# Max pooling; 7 by 7 by 128 to 4 by 4 by 128\n",
    "A4 = P4 = tf.nn.max_pool(Z4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# ==================================================\n",
    "# Flatten layer; 4 by 4 with 128 activation maps\n",
    "# ==================================================\n",
    "A4_flat = P4_flat = tf.reshape(A4, [-1, 128*4*4])\n",
    "\n",
    "# ==================================================\n",
    "# Output layer\n",
    "# ==================================================\n",
    "W5 = tf.Variable(tf.random_normal([128*4*4, 10], stddev=0.01))\n",
    "B5 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# Linear regression\n",
    "Z5 = logits = tf.matmul(A4_flat, W5) + B5\n",
    "\n",
    "Y = A5 = tf.nn.softmax(Z5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z5, labels=T))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# Compare batch_size X by argmax\n",
    "predicted_val = tf.equal(tf.argmax(A5, 1), tf.argmax(T, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.9522107\n",
      "epochs =  0 , step =  100 , loss_val =  0.32884076\n",
      "epochs =  0 , step =  200 , loss_val =  0.191569\n",
      "epochs =  0 , step =  300 , loss_val =  0.06670697\n",
      "epochs =  0 , step =  400 , loss_val =  0.03884934\n",
      "epochs =  0 , step =  500 , loss_val =  0.06051705\n",
      "epochs =  1 , step =  0 , loss_val =  0.09091077\n",
      "epochs =  1 , step =  100 , loss_val =  0.04238449\n",
      "epochs =  1 , step =  200 , loss_val =  0.043678373\n",
      "epochs =  1 , step =  300 , loss_val =  0.12371366\n",
      "epochs =  1 , step =  400 , loss_val =  0.032980304\n",
      "epochs =  1 , step =  500 , loss_val =  0.009329795\n",
      "epochs =  2 , step =  0 , loss_val =  0.043739438\n",
      "epochs =  2 , step =  100 , loss_val =  0.015929034\n",
      "epochs =  2 , step =  200 , loss_val =  0.05139128\n",
      "epochs =  2 , step =  300 , loss_val =  0.01417461\n",
      "epochs =  2 , step =  400 , loss_val =  0.03695252\n",
      "epochs =  2 , step =  500 , loss_val =  0.058533538\n",
      "epochs =  3 , step =  0 , loss_val =  0.010159563\n",
      "epochs =  3 , step =  100 , loss_val =  0.038255304\n",
      "epochs =  3 , step =  200 , loss_val =  0.022138765\n",
      "epochs =  3 , step =  300 , loss_val =  0.016105779\n",
      "epochs =  3 , step =  400 , loss_val =  0.039168056\n",
      "epochs =  3 , step =  500 , loss_val =  0.007806112\n",
      "epochs =  4 , step =  0 , loss_val =  0.030236911\n",
      "epochs =  4 , step =  100 , loss_val =  0.022323431\n",
      "epochs =  4 , step =  200 , loss_val =  0.022458384\n",
      "epochs =  4 , step =  300 , loss_val =  0.015427959\n",
      "epochs =  4 , step =  400 , loss_val =  0.15838921\n",
      "epochs =  4 , step =  500 , loss_val =  0.0054232227\n",
      "epochs =  5 , step =  0 , loss_val =  0.014196026\n",
      "epochs =  5 , step =  100 , loss_val =  0.017038606\n",
      "epochs =  5 , step =  200 , loss_val =  0.015726142\n",
      "epochs =  5 , step =  300 , loss_val =  0.012678198\n",
      "epochs =  5 , step =  400 , loss_val =  0.0195732\n",
      "epochs =  5 , step =  500 , loss_val =  0.02372408\n",
      "epochs =  6 , step =  0 , loss_val =  0.017430034\n",
      "epochs =  6 , step =  100 , loss_val =  0.030839546\n",
      "epochs =  6 , step =  200 , loss_val =  0.13191456\n",
      "epochs =  6 , step =  300 , loss_val =  0.041077938\n",
      "epochs =  6 , step =  400 , loss_val =  0.018500559\n",
      "epochs =  6 , step =  500 , loss_val =  0.018411068\n",
      "epochs =  7 , step =  0 , loss_val =  0.002562514\n",
      "epochs =  7 , step =  100 , loss_val =  0.03220161\n",
      "epochs =  7 , step =  200 , loss_val =  0.18236901\n",
      "epochs =  7 , step =  300 , loss_val =  0.02951406\n",
      "epochs =  7 , step =  400 , loss_val =  0.01650343\n",
      "epochs =  7 , step =  500 , loss_val =  0.009263591\n",
      "epochs =  8 , step =  0 , loss_val =  0.011579208\n",
      "epochs =  8 , step =  100 , loss_val =  0.0072048483\n",
      "epochs =  8 , step =  200 , loss_val =  0.020000413\n",
      "epochs =  8 , step =  300 , loss_val =  0.00026526581\n",
      "epochs =  8 , step =  400 , loss_val =  0.0015276748\n",
      "epochs =  8 , step =  500 , loss_val =  0.03413905\n",
      "epochs =  9 , step =  0 , loss_val =  0.079653144\n",
      "epochs =  9 , step =  100 , loss_val =  0.0012415265\n",
      "epochs =  9 , step =  200 , loss_val =  0.0019368092\n",
      "epochs =  9 , step =  300 , loss_val =  0.03127524\n",
      "epochs =  9 , step =  400 , loss_val =  0.0015764378\n",
      "epochs =  9 , step =  500 , loss_val =  0.05923889\n",
      "epochs =  10 , step =  0 , loss_val =  0.0028321939\n",
      "epochs =  10 , step =  100 , loss_val =  1.5637377e-05\n",
      "epochs =  10 , step =  200 , loss_val =  0.00024411963\n",
      "epochs =  10 , step =  300 , loss_val =  0.035297345\n",
      "epochs =  10 , step =  400 , loss_val =  0.15810463\n",
      "epochs =  10 , step =  500 , loss_val =  0.03592977\n",
      "epochs =  11 , step =  0 , loss_val =  0.030365627\n",
      "epochs =  11 , step =  100 , loss_val =  0.023085799\n",
      "epochs =  11 , step =  200 , loss_val =  0.046519805\n",
      "epochs =  11 , step =  300 , loss_val =  0.005635523\n",
      "epochs =  11 , step =  400 , loss_val =  0.024276385\n",
      "epochs =  11 , step =  500 , loss_val =  0.0023205618\n",
      "epochs =  12 , step =  0 , loss_val =  0.014387905\n",
      "epochs =  12 , step =  100 , loss_val =  0.049004074\n",
      "epochs =  12 , step =  200 , loss_val =  0.0013978874\n",
      "epochs =  12 , step =  300 , loss_val =  0.0035434726\n",
      "epochs =  12 , step =  400 , loss_val =  0.00047003184\n",
      "epochs =  12 , step =  500 , loss_val =  0.055444445\n",
      "epochs =  13 , step =  0 , loss_val =  0.002573192\n",
      "epochs =  13 , step =  100 , loss_val =  0.010618483\n",
      "epochs =  13 , step =  200 , loss_val =  0.011799696\n",
      "epochs =  13 , step =  300 , loss_val =  0.028323397\n",
      "epochs =  13 , step =  400 , loss_val =  0.042744346\n",
      "epochs =  13 , step =  500 , loss_val =  0.13280123\n",
      "epochs =  14 , step =  0 , loss_val =  0.04470077\n",
      "epochs =  14 , step =  100 , loss_val =  0.109449156\n",
      "epochs =  14 , step =  200 , loss_val =  0.034318022\n",
      "epochs =  14 , step =  300 , loss_val =  0.032433327\n",
      "epochs =  14 , step =  400 , loss_val =  0.060888425\n",
      "epochs =  14 , step =  500 , loss_val =  0.067216486\n",
      "epochs =  15 , step =  0 , loss_val =  0.05514203\n",
      "epochs =  15 , step =  100 , loss_val =  0.059909202\n",
      "epochs =  15 , step =  200 , loss_val =  3.0634121e-06\n",
      "epochs =  15 , step =  300 , loss_val =  0.0021005776\n",
      "epochs =  15 , step =  400 , loss_val =  0.045129627\n",
      "epochs =  15 , step =  500 , loss_val =  0.03071194\n",
      "epochs =  16 , step =  0 , loss_val =  3.5497007e-05\n",
      "epochs =  16 , step =  100 , loss_val =  0.065323345\n",
      "epochs =  16 , step =  200 , loss_val =  0.0023469147\n",
      "epochs =  16 , step =  300 , loss_val =  0.03335685\n",
      "epochs =  16 , step =  400 , loss_val =  0.007998865\n",
      "epochs =  16 , step =  500 , loss_val =  0.003898217\n",
      "epochs =  17 , step =  0 , loss_val =  0.02612976\n",
      "epochs =  17 , step =  100 , loss_val =  0.15785855\n",
      "epochs =  17 , step =  200 , loss_val =  0.0010602679\n",
      "epochs =  17 , step =  300 , loss_val =  0.0001331401\n",
      "epochs =  17 , step =  400 , loss_val =  0.011879278\n",
      "epochs =  17 , step =  500 , loss_val =  0.026613403\n",
      "epochs =  18 , step =  0 , loss_val =  0.02086652\n",
      "epochs =  18 , step =  100 , loss_val =  0.018100511\n",
      "epochs =  18 , step =  200 , loss_val =  0.00031962787\n",
      "epochs =  18 , step =  300 , loss_val =  0.005002246\n",
      "epochs =  18 , step =  400 , loss_val =  0.00021004934\n",
      "epochs =  18 , step =  500 , loss_val =  0.0076431767\n",
      "epochs =  19 , step =  0 , loss_val =  0.0015156098\n",
      "epochs =  19 , step =  100 , loss_val =  3.0001258e-05\n",
      "epochs =  19 , step =  200 , loss_val =  0.00070140354\n",
      "epochs =  19 , step =  300 , loss_val =  0.18849093\n",
      "epochs =  19 , step =  400 , loss_val =  0.000108663866\n",
      "epochs =  19 , step =  500 , loss_val =  0.035320856\n",
      "epochs =  20 , step =  0 , loss_val =  0.0008234285\n",
      "epochs =  20 , step =  100 , loss_val =  7.165119e-05\n",
      "epochs =  20 , step =  200 , loss_val =  0.0060038054\n",
      "epochs =  20 , step =  300 , loss_val =  4.129689e-05\n",
      "epochs =  20 , step =  400 , loss_val =  0.0026782202\n",
      "epochs =  20 , step =  500 , loss_val =  0.15722857\n",
      "epochs =  21 , step =  0 , loss_val =  0.00068995624\n",
      "epochs =  21 , step =  100 , loss_val =  1.0241234e-05\n",
      "epochs =  21 , step =  200 , loss_val =  1.6640947e-06\n",
      "epochs =  21 , step =  300 , loss_val =  0.001445386\n",
      "epochs =  21 , step =  400 , loss_val =  0.0007616103\n",
      "epochs =  21 , step =  500 , loss_val =  0.00983435\n",
      "epochs =  22 , step =  0 , loss_val =  9.9829806e-05\n",
      "epochs =  22 , step =  100 , loss_val =  0.0008365228\n",
      "epochs =  22 , step =  200 , loss_val =  0.14101656\n",
      "epochs =  22 , step =  300 , loss_val =  0.0004441358\n",
      "epochs =  22 , step =  400 , loss_val =  7.78255e-06\n",
      "epochs =  22 , step =  500 , loss_val =  0.1385952\n",
      "epochs =  23 , step =  0 , loss_val =  0.06785865\n",
      "epochs =  23 , step =  100 , loss_val =  2.2649742e-08\n",
      "epochs =  23 , step =  200 , loss_val =  2.1182582e-06\n",
      "epochs =  23 , step =  300 , loss_val =  0.0007068537\n",
      "epochs =  23 , step =  400 , loss_val =  0.0005535962\n",
      "epochs =  23 , step =  500 , loss_val =  0.00011002057\n",
      "epochs =  24 , step =  0 , loss_val =  6.4013454e-07\n",
      "epochs =  24 , step =  100 , loss_val =  0.26284686\n",
      "epochs =  24 , step =  200 , loss_val =  0.01355518\n",
      "epochs =  24 , step =  300 , loss_val =  0.04731848\n",
      "epochs =  24 , step =  400 , loss_val =  0.0002720003\n",
      "epochs =  24 , step =  500 , loss_val =  0.0008314374\n",
      "epochs =  25 , step =  0 , loss_val =  5.698081e-07\n",
      "epochs =  25 , step =  100 , loss_val =  0.002151391\n",
      "epochs =  25 , step =  200 , loss_val =  0.00015047453\n",
      "epochs =  25 , step =  300 , loss_val =  4.8614097e-06\n",
      "epochs =  25 , step =  400 , loss_val =  0.021257319\n",
      "epochs =  25 , step =  500 , loss_val =  0.00024646355\n",
      "epochs =  26 , step =  0 , loss_val =  0.2152001\n",
      "epochs =  26 , step =  100 , loss_val =  0.13947028\n",
      "epochs =  26 , step =  200 , loss_val =  0.052282497\n",
      "epochs =  26 , step =  300 , loss_val =  0.0007556676\n",
      "epochs =  26 , step =  400 , loss_val =  2.403757e-05\n",
      "epochs =  26 , step =  500 , loss_val =  0.00061435567\n",
      "epochs =  27 , step =  0 , loss_val =  0.018004842\n",
      "epochs =  27 , step =  100 , loss_val =  0.0005028185\n",
      "epochs =  27 , step =  200 , loss_val =  0.012787231\n",
      "epochs =  27 , step =  300 , loss_val =  0.19599217\n",
      "epochs =  27 , step =  400 , loss_val =  0.0068170596\n",
      "epochs =  27 , step =  500 , loss_val =  0.0257093\n",
      "epochs =  28 , step =  0 , loss_val =  0.04455317\n",
      "epochs =  28 , step =  100 , loss_val =  3.1112697e-05\n",
      "epochs =  28 , step =  200 , loss_val =  0.027662573\n",
      "epochs =  28 , step =  300 , loss_val =  5.5253568e-05\n",
      "epochs =  28 , step =  400 , loss_val =  2.9082926e-06\n",
      "epochs =  28 , step =  500 , loss_val =  0.028934166\n",
      "epochs =  29 , step =  0 , loss_val =  0.03978886\n",
      "epochs =  29 , step =  100 , loss_val =  5.135264e-05\n",
      "epochs =  29 , step =  200 , loss_val =  0.06661476\n",
      "epochs =  29 , step =  300 , loss_val =  0.029702721\n",
      "epochs =  29 , step =  400 , loss_val =  0.059700422\n",
      "epochs =  29 , step =  500 , loss_val =  0.13250557\n",
      "\n",
      "elapsed time =  0:19:33.753510\n",
      "\n",
      "Accuracy =  0.9849\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize tf.Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)   # 55,000 / 100\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            \n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\\nelapsed time = \", end_time - start_time)\n",
    "    \n",
    "    # Accuracy\n",
    "    test_x_data = mnist.test.images     # 10000 * 784\n",
    "    test_t_data = mnist.test.labels     # 10000 * 10\n",
    "    \n",
    "    accuracy_val = sess.run(accuracy, feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy = \", accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
